{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import scipy.sparse as sps\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         row    col  data\n",
       "0          0  10080   1.0\n",
       "1          0  19467   1.0\n",
       "2          1   2665   1.0\n",
       "3          1   7494   1.0\n",
       "4          1  17068   1.0\n",
       "...      ...    ...   ...\n",
       "113263  7945   2476   1.0\n",
       "113264  7945  12319   1.0\n",
       "113265  7945  21384   1.0\n",
       "113266  7946   8699   1.0\n",
       "113267  7946  19178   1.0\n",
       "\n",
       "[113268 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row</th>\n      <th>col</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10080</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>19467</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2665</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>7494</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>17068</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>113263</th>\n      <td>7945</td>\n      <td>2476</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>113264</th>\n      <td>7945</td>\n      <td>12319</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>113265</th>\n      <td>7945</td>\n      <td>21384</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>113266</th>\n      <td>7946</td>\n      <td>8699</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>113267</th>\n      <td>7946</td>\n      <td>19178</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>113268 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#data which contains users (row), items(col) and implicit interaction (data)\n",
    "dataset = pd.read_csv('../data_train.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7947, 25975)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "users = dataset.row\n",
    "items = dataset.col\n",
    "data = dataset.data\n",
    "URM_all = sps.coo_matrix((data, (users, items)))\n",
    "URM_all = URM_all.tocsr() #fast row access -> fast access to users \n",
    "URM_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          row    col      data\n",
       "0           0   1185  1.015524\n",
       "1           0   2507  0.459024\n",
       "2           0   3534  0.227742\n",
       "3           0   8766  0.501549\n",
       "4           0  10862  0.297011\n",
       "...       ...    ...       ...\n",
       "490686  25974  12554  0.963016\n",
       "490687  25974  13003  0.104613\n",
       "490688  25974  16236  0.118760\n",
       "490689  25974  18797  0.363301\n",
       "490690  25974  19629  0.129141\n",
       "\n",
       "[490691 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row</th>\n      <th>col</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1185</td>\n      <td>1.015524</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2507</td>\n      <td>0.459024</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>3534</td>\n      <td>0.227742</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>8766</td>\n      <td>0.501549</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>10862</td>\n      <td>0.297011</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>490686</th>\n      <td>25974</td>\n      <td>12554</td>\n      <td>0.963016</td>\n    </tr>\n    <tr>\n      <th>490687</th>\n      <td>25974</td>\n      <td>13003</td>\n      <td>0.104613</td>\n    </tr>\n    <tr>\n      <th>490688</th>\n      <td>25974</td>\n      <td>16236</td>\n      <td>0.118760</td>\n    </tr>\n    <tr>\n      <th>490689</th>\n      <td>25974</td>\n      <td>18797</td>\n      <td>0.363301</td>\n    </tr>\n    <tr>\n      <th>490690</th>\n      <td>25974</td>\n      <td>19629</td>\n      <td>0.129141</td>\n    </tr>\n  </tbody>\n</table>\n<p>490691 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "ICM_df = pd.read_csv('../data_ICM_title_abstract.csv')\n",
    "ICM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(25975, 20000)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "items = ICM_df.row\n",
    "features = ICM_df.col\n",
    "data = ICM_df.data\n",
    "ICM_all = sps.coo_matrix((data, (items, features)))\n",
    "ICM_all = ICM_all.tocsr() #fast row access -> fast access to users \n",
    "ICM_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: 35 (0.44 %) of 7947 users have no train items\nWarning: 2948 (37.10 %) of 7947 users have no sampled items\n"
     ]
    }
   ],
   "source": [
    "from Base.Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "\n",
    "URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MatrixFactorization.Cython._MatrixFactorization_Cython'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-58506ab65925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInteger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mMatrixFactorization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MatrixFactorization_Cython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MatrixFactorization_Cython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mParameterTuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSearchAbstractClass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSearchInputRecommenderArgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mParameterTuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSearchBayesianSkopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSearchBayesianSkopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MatrixFactorization.Cython._MatrixFactorization_Cython'"
     ]
    }
   ],
   "source": [
    "from skopt.space import Real, Integer, Categorical\n",
    "from MatrixFactorization.Cython._MatrixFactorization_Cython import _MatrixFactorization_Cython\n",
    "from ParameterTuning.SearchAbstractClass import SearchInputRecommenderArgs\n",
    "from ParameterTuning.SearchBayesianSkopt import SearchBayesianSkopt\n",
    "\n",
    "hyperparameters_range_dictionary = {}\n",
    "hyperparameters_range_dictionary[\"num_factors\"] = Integer(1, 200)\n",
    "hyperparameters_range_dictionary[\"batch_size\"] = Integer(1, 1000)\n",
    "hyperparameters_range_dictionary[\"learning_rate\"] = Real(low = 0.001, high = 0.1, prior = 'log-uniform')\n",
    "\n",
    "grouped_users = dataset.groupby(['row']).count()\n",
    "\n",
    "# All users present into the dataser\n",
    "sorted_users = grouped_users.sort_values(by=['col'], ascending=True)\n",
    "sorted_users = sorted_users.index.to_numpy()\n",
    "print(len(sorted_users))\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n",
    "\n",
    "recommender_class = IALSRecommender\n",
    "\n",
    "parameterSearch = SearchBayesianSkopt(recommender_class,\n",
    "                                 evaluator_validation=evaluator_validation,\n",
    "                                 evaluator_test=evaluator_validation)\n",
    "\n",
    "import os\n",
    "\n",
    "output_folder_path = \"result_experiments/\"\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "    \n",
    "n_cases = 10\n",
    "n_random_starts = int(n_cases*0.3)\n",
    "\n",
    "metric_to_optimize = \"MAP\" \n",
    "evaluator_validation_earlystopping = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n",
    "\n",
    "earlystopping_keywargs = {\"validation_every_n\": 5,\n",
    "                              \"stop_on_validation\": True,\n",
    "                              \"evaluator_object\": evaluator_validation_earlystopping,\n",
    "                              \"lower_validations_allowed\": 5,\n",
    "                              \"validation_metric\": metric_to_optimize,\n",
    "                              }\n",
    "\n",
    "recommender_input_args = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [URM_train],\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS = earlystopping_keywargs\n",
    ")\n",
    "\n",
    "recommender_input_args_last_test = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [URM_all],\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS = earlystopping_keywargs\n",
    ")\n",
    "\n",
    "\n",
    "parameterSearch.search(recommender_input_args,\n",
    "                       recommender_input_args_last_test = recommender_input_args_last_test,\n",
    "                       parameter_search_space = hyperparameters_range_dictionary,\n",
    "                       n_cases = n_cases,\n",
    "                       n_random_starts = n_random_starts,\n",
    "                       save_model = \"last\",\n",
    "                       output_folder_path = output_folder_path,\n",
    "                       output_file_name_root = recommender_class.RECOMMENDER_NAME,\n",
    "                       metric_to_optimize = metric_to_optimize,\n",
    "                      )\n",
    "\n",
    "from Base.DataIO import DataIO\n",
    "\n",
    "data_loader = DataIO(folder_path = output_folder_path)\n",
    "\n",
    "search_metadata = data_loader.load_data(recommender_class.RECOMMENDER_NAME + \"_metadata.zip\")\n",
    "\n",
    "hyperparameters_list = search_metadata[\"hyperparameters_list\"]\n",
    "\n",
    "best_parameters = search_metadata[\"hyperparameters_best\"]\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = pd.read_csv('data_target_users_test.csv')\n",
    "test_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_alpha = P3alphaRecommender(URM_all)\n",
    "recommender_alpha.fit(topK=475, alpha = 0.45, implicit = True)\n",
    "\n",
    "recommender_alpha_ICM = P3alphaRecommender(ICM_all.T)\n",
    "recommender_alpha_ICM.fit(topK=175, alpha = 0.45)\n",
    "recommender_alpha_ICM.URM_train = URM_train\n",
    "\n",
    "hybridrecommender = ItemKNNSimilarityHybridRecommender(URM_all, recommender_alpha_ICM.W_sparse, recommender_alpha.W_sparse)\n",
    "hybridrecommender.fit(topK=600, alpha = 0.45)\n",
    "\n",
    "user_id = test_users['user_id']\n",
    "recommendations = hybridrecommender.recommend(user_id,cutoff = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(recommendations)):\n",
    "    #print(element)\n",
    "    recommendations[index]=np.array(recommendations[index])\n",
    "    #print(type(element))\n",
    "print(len(recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users['item_list']= recommendations\n",
    "#test_users['item_list'] =  test_users['item_list'].apply(lambda x: x.replace('[','').replace(']','')) \n",
    "test_users['item_list'] = pd.DataFrame([str(line).strip('[').strip(']').replace(\"'\",\"\") for line in test_users['item_list']])\n",
    "\n",
    "#convert the string columns to int\n",
    "#test_users['item_list'] = test_users['item_list'].astype(int)\n",
    "test_users\n",
    "test_users.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('RecSysFramework')",
   "metadata": {
    "interpreter": {
     "hash": "51a80ca21be2b4132a5304adc27cee52aa155931557717378c98cb6d506e4e7c"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}